{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCENIC+ and PINNACLE Integration: Interactive Analysis\n",
    "\n",
    "This notebook demonstrates the interactive analysis capabilities of the SCENIC+ and PINNACLE integration framework.\n",
    "\n",
    "## Overview\n",
    "\n",
    "This tutorial covers:\n",
    "1. Loading and preprocessing data\n",
    "2. Network integration\n",
    "3. Differential analysis\n",
    "4. Interactive visualizations\n",
    "5. Results interpretation\n",
    "\n",
    "**Author:** Manus AI  \n",
    "**Date:** July 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import the integration package\n",
    "from scenic_pinnacle import (\n",
    "    ScenicPinnacleIntegrator,\n",
    "    ScenicProcessor,\n",
    "    PinnacleProcessor,\n",
    "    NetworkIntegrator,\n",
    "    DifferentialAnalyzer,\n",
    "    NetworkVisualizer\n",
    ")\n",
    "\n",
    "# Set up plotting\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration and Setup\n",
    "\n",
    "First, let's set up the configuration for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for the integration\n",
    "config = {\n",
    "    'scenic': {\n",
    "        'min_regulon_size': 10,\n",
    "        'min_target_genes': 5,\n",
    "        'importance_threshold': 0.1\n",
    "    },\n",
    "    'pinnacle': {\n",
    "        'embedding_dim': 256,\n",
    "        'normalize_embeddings': True,\n",
    "        'context_threshold': 0.1\n",
    "    },\n",
    "    'integration': {\n",
    "        'similarity_threshold': 0.5,\n",
    "        'min_overlap': 3\n",
    "    },\n",
    "    'differential': {\n",
    "        'pvalue_threshold': 0.05,\n",
    "        'fold_change_threshold': 1.5\n",
    "    },\n",
    "    'visualization': {\n",
    "        'layout_algorithm': 'spring',\n",
    "        'node_size_range': (20, 200),\n",
    "        'edge_width_range': (0.5, 3.0)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Data paths (modify these to point to your data)\n",
    "data_dir = Path(\"../data\")\n",
    "scenic_data_path = data_dir / \"scenic_networks.pkl\"\n",
    "pinnacle_data_path = data_dir / \"pinnacle_embeddings.pkl\"\n",
    "output_dir = Path(\"../results/interactive_analysis\")\n",
    "\n",
    "# Create output directory\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Configuration set up successfully!\")\n",
    "print(f\"Output directory: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize the Integrator\n",
    "\n",
    "Create the main integrator object that will coordinate the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the integrator\n",
    "integrator = ScenicPinnacleIntegrator(config=config)\n",
    "\n",
    "print(\"Integrator initialized successfully!\")\n",
    "print(f\"Available processors:\")\n",
    "print(f\"  - SCENIC+ processor: {type(integrator.scenic_processor).__name__}\")\n",
    "print(f\"  - PINNACLE processor: {type(integrator.pinnacle_processor).__name__}\")\n",
    "print(f\"  - Network integrator: {type(integrator.network_integrator).__name__}\")\n",
    "print(f\"  - Differential analyzer: {type(integrator.differential_analyzer).__name__}\")\n",
    "print(f\"  - Visualizer: {type(integrator.visualizer).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate Example Data\n",
    "\n",
    "For this tutorial, we'll generate example data. In practice, you would load your own SCENIC+ and PINNACLE results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_example_data():\n",
    "    \"\"\"Generate example SCENIC+ and PINNACLE data.\"\"\"\n",
    "    import pickle\n",
    "    \n",
    "    # Create data directory\n",
    "    data_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Generate SCENIC+ networks\n",
    "    scenic_networks = {}\n",
    "    conditions = ['healthy', 'disease', 'treatment']\n",
    "    \n",
    "    for i, condition in enumerate(conditions):\n",
    "        G = nx.DiGraph()\n",
    "        \n",
    "        # Add transcription factors\n",
    "        tfs = [f'TF_{j}' for j in range(1, 16)]  # 15 TFs\n",
    "        for tf in tfs:\n",
    "            G.add_node(tf, node_type='TF')\n",
    "        \n",
    "        # Add target genes\n",
    "        targets = [f'Gene_{j}' for j in range(1, 101)]  # 100 targets\n",
    "        for target in targets:\n",
    "            G.add_node(target, node_type='target')\n",
    "        \n",
    "        # Add regulatory edges with condition-specific patterns\n",
    "        np.random.seed(42 + i)\n",
    "        for tf_idx, tf in enumerate(tfs):\n",
    "            # Each TF regulates 10-20 targets\n",
    "            n_targets = np.random.randint(10, 21)\n",
    "            \n",
    "            # Add condition-specific bias\n",
    "            if condition == 'disease':\n",
    "                # Disease condition has stronger regulation for some TFs\n",
    "                if tf_idx < 5:\n",
    "                    importance_boost = 0.3\n",
    "                else:\n",
    "                    importance_boost = 0.0\n",
    "            elif condition == 'treatment':\n",
    "                # Treatment condition has different pattern\n",
    "                if tf_idx >= 10:\n",
    "                    importance_boost = 0.4\n",
    "                else:\n",
    "                    importance_boost = -0.1\n",
    "            else:\n",
    "                importance_boost = 0.0\n",
    "            \n",
    "            selected_targets = np.random.choice(targets, n_targets, replace=False)\n",
    "            \n",
    "            for target in selected_targets:\n",
    "                base_importance = np.random.uniform(0.2, 0.8)\n",
    "                importance = np.clip(base_importance + importance_boost, 0.1, 1.0)\n",
    "                \n",
    "                G.add_edge(tf, target, \n",
    "                          importance=importance,\n",
    "                          edge_type='regulation',\n",
    "                          enhancer=f'Enhancer_{np.random.randint(1, 1000)}')\n",
    "        \n",
    "        scenic_networks[condition] = G\n",
    "    \n",
    "    # Save SCENIC+ data\n",
    "    with open(scenic_data_path, 'wb') as f:\n",
    "        pickle.dump(scenic_networks, f)\n",
    "    \n",
    "    # Generate PINNACLE embeddings\n",
    "    pinnacle_embeddings = {}\n",
    "    \n",
    "    # Create protein list\n",
    "    all_genes = [f'TF_{j}' for j in range(1, 16)] + [f'Gene_{j}' for j in range(1, 101)]\n",
    "    protein_ids = [f'Protein_{gene}' for gene in all_genes]\n",
    "    \n",
    "    for i, condition in enumerate(conditions):\n",
    "        np.random.seed(123 + i)\n",
    "        \n",
    "        # Generate embeddings with condition-specific structure\n",
    "        embeddings = np.random.randn(len(protein_ids), 256) * 0.5\n",
    "        \n",
    "        # Add condition-specific clustering\n",
    "        if condition == 'healthy':\n",
    "            # TF proteins form one cluster\n",
    "            embeddings[:15] += np.array([1.0, 0.0] + [0.0] * 254)\n",
    "            # Target proteins form another cluster\n",
    "            embeddings[15:] += np.array([0.0, 1.0] + [0.0] * 254)\n",
    "        elif condition == 'disease':\n",
    "            # Different clustering pattern\n",
    "            embeddings[:15] += np.array([0.5, 0.5] + [0.0] * 254)\n",
    "            embeddings[15:50] += np.array([1.5, 0.0] + [0.0] * 254)\n",
    "            embeddings[50:] += np.array([0.0, 1.5] + [0.0] * 254)\n",
    "        else:  # treatment\n",
    "            # Treatment restores some structure\n",
    "            embeddings[:15] += np.array([0.8, 0.2] + [0.0] * 254)\n",
    "            embeddings[15:] += np.array([0.2, 0.8] + [0.0] * 254)\n",
    "        \n",
    "        # Normalize embeddings\n",
    "        norms = np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
    "        norms[norms == 0] = 1\n",
    "        embeddings = embeddings / norms\n",
    "        \n",
    "        pinnacle_embeddings[condition] = {\n",
    "            'embeddings': embeddings,\n",
    "            'protein_ids': protein_ids,\n",
    "            'embedding_dim': 256\n",
    "        }\n",
    "    \n",
    "    # Save PINNACLE data\n",
    "    with open(pinnacle_data_path, 'wb') as f:\n",
    "        pickle.dump(pinnacle_embeddings, f)\n",
    "    \n",
    "    return scenic_networks, pinnacle_embeddings\n",
    "\n",
    "# Generate example data\n",
    "print(\"Generating example data...\")\n",
    "scenic_networks, pinnacle_embeddings = generate_example_data()\n",
    "\n",
    "print(f\"Generated SCENIC+ networks for conditions: {list(scenic_networks.keys())}\")\n",
    "print(f\"Generated PINNACLE embeddings for conditions: {list(pinnacle_embeddings.keys())}\")\n",
    "\n",
    "# Display network statistics\n",
    "print(\"\\nNetwork Statistics:\")\n",
    "for condition, network in scenic_networks.items():\n",
    "    print(f\"  {condition}: {network.number_of_nodes()} nodes, {network.number_of_edges()} edges\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load Data\n",
    "\n",
    "Load the SCENIC+ and PINNACLE data into the integrator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SCENIC+ data\n",
    "print(\"Loading SCENIC+ data...\")\n",
    "integrator.load_scenic_data(scenic_data_path, data_format='pickle')\n",
    "print(f\"Loaded {len(integrator.scenic_networks)} SCENIC+ networks\")\n",
    "\n",
    "# Load PINNACLE data\n",
    "print(\"\\nLoading PINNACLE data...\")\n",
    "integrator.load_pinnacle_data(pinnacle_data_path, data_format='pickle')\n",
    "print(f\"Loaded embeddings for {len(integrator.pinnacle_embeddings)} contexts\")\n",
    "\n",
    "# Display loaded data summary\n",
    "print(\"\\nLoaded Data Summary:\")\n",
    "print(\"SCENIC+ Networks:\")\n",
    "for condition, network in integrator.scenic_networks.items():\n",
    "    tfs = sum(1 for n in network.nodes() if network.nodes[n].get('node_type') == 'TF')\n",
    "    targets = sum(1 for n in network.nodes() if network.nodes[n].get('node_type') == 'target')\n",
    "    print(f\"  {condition}: {tfs} TFs, {targets} targets, {network.number_of_edges()} regulations\")\n",
    "\n",
    "print(\"\\nPINNACLE Embeddings:\")\n",
    "for condition, embeddings in integrator.pinnacle_embeddings.items():\n",
    "    print(f\"  {condition}: {len(embeddings['protein_ids'])} proteins, {embeddings['embedding_dim']}D embeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Network Integration\n",
    "\n",
    "Integrate the SCENIC+ regulatory networks with PINNACLE protein embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform network integration\n",
    "print(\"Integrating networks...\")\n",
    "integrated_networks = integrator.integrate_networks()\n",
    "\n",
    "print(f\"\\nIntegration completed! Created {len(integrated_networks)} integrated networks.\")\n",
    "\n",
    "# Display integration statistics\n",
    "print(\"\\nIntegrated Network Statistics:\")\n",
    "for condition, network in integrated_networks.items():\n",
    "    print(f\"\\n{condition}:\")\n",
    "    print(f\"  Nodes: {network.number_of_nodes()}\")\n",
    "    print(f\"  Edges: {network.number_of_edges()}\")\n",
    "    print(f\"  Density: {nx.density(network):.4f}\")\n",
    "    \n",
    "    # Edge type distribution\n",
    "    edge_types = {}\n",
    "    for _, _, data in network.edges(data=True):\n",
    "        edge_type = data.get('edge_type', 'unknown')\n",
    "        edge_types[edge_type] = edge_types.get(edge_type, 0) + 1\n",
    "    \n",
    "    print(f\"  Edge types: {edge_types}\")\n",
    "    \n",
    "    # Node type distribution\n",
    "    node_types = {}\n",
    "    for node in network.nodes():\n",
    "        node_type = network.nodes[node].get('node_type', 'unknown')\n",
    "        node_types[node_type] = node_types.get(node_type, 0) + 1\n",
    "    \n",
    "    print(f\"  Node types: {node_types}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Differential Analysis\n",
    "\n",
    "Perform differential analysis between conditions to identify changes in regulatory and protein networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform differential analysis between healthy and disease conditions\n",
    "print(\"Performing differential analysis: healthy vs disease...\")\n",
    "diff_results_1 = integrator.differential_analysis('healthy', 'disease', analysis_type='both')\n",
    "\n",
    "# Perform differential analysis between disease and treatment conditions\n",
    "print(\"Performing differential analysis: disease vs treatment...\")\n",
    "diff_results_2 = integrator.differential_analysis('disease', 'treatment', analysis_type='both')\n",
    "\n",
    "# Display differential analysis results\n",
    "print(\"\\nDifferential Analysis Results:\")\n",
    "print(\"\\n1. Healthy vs Disease:\")\n",
    "summary_1 = diff_results_1.get('summary', {})\n",
    "for analysis_type, stats in summary_1.items():\n",
    "    print(f\"   {analysis_type.title()}:\")\n",
    "    for stat_name, value in stats.items():\n",
    "        print(f\"     {stat_name}: {value}\")\n",
    "\n",
    "print(\"\\n2. Disease vs Treatment:\")\n",
    "summary_2 = diff_results_2.get('summary', {})\n",
    "for analysis_type, stats in summary_2.items():\n",
    "    print(f\"   {analysis_type.title()}:\")\n",
    "    for stat_name, value in stats.items():\n",
    "        print(f\"     {stat_name}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualizations\n",
    "\n",
    "Create various visualizations to explore the integrated networks and differential analysis results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create network visualizations\n",
    "print(\"Creating network visualizations...\")\n",
    "\n",
    "# Visualize each integrated network\n",
    "for condition in ['healthy', 'disease', 'treatment']:\n",
    "    if condition in integrated_networks:\n",
    "        print(f\"\\nVisualizing {condition} network...\")\n",
    "        \n",
    "        # Create output directory for this condition\n",
    "        condition_dir = output_dir / condition\n",
    "        condition_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Generate different types of plots\n",
    "        integrator.visualize_networks(\n",
    "            condition, \n",
    "            condition_dir,\n",
    "            plot_types=['network', 'heatmap']\n",
    "        )\n",
    "        \n",
    "        print(f\"   Saved visualizations to {condition_dir}\")\n",
    "\n",
    "print(\"\\nNetwork visualizations completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create differential analysis visualizations\n",
    "print(\"Creating differential analysis visualizations...\")\n",
    "\n",
    "# Visualize differential results\n",
    "visualizer = integrator.visualizer\n",
    "\n",
    "# Healthy vs Disease\n",
    "diff_dir_1 = output_dir / 'differential_healthy_vs_disease'\n",
    "diff_dir_1.mkdir(exist_ok=True)\n",
    "\n",
    "visualizer.plot_differential_analysis(\n",
    "    diff_results_1,\n",
    "    diff_dir_1 / 'volcano_plot.png',\n",
    "    plot_type='volcano'\n",
    ")\n",
    "\n",
    "visualizer.plot_differential_analysis(\n",
    "    diff_results_1,\n",
    "    diff_dir_1 / 'summary_heatmap.png',\n",
    "    plot_type='heatmap'\n",
    ")\n",
    "\n",
    "visualizer.plot_differential_analysis(\n",
    "    diff_results_1,\n",
    "    diff_dir_1 / 'summary_barplot.png',\n",
    "    plot_type='barplot'\n",
    ")\n",
    "\n",
    "# Disease vs Treatment\n",
    "diff_dir_2 = output_dir / 'differential_disease_vs_treatment'\n",
    "diff_dir_2.mkdir(exist_ok=True)\n",
    "\n",
    "visualizer.plot_differential_analysis(\n",
    "    diff_results_2,\n",
    "    diff_dir_2 / 'volcano_plot.png',\n",
    "    plot_type='volcano'\n",
    ")\n",
    "\n",
    "visualizer.plot_differential_analysis(\n",
    "    diff_results_2,\n",
    "    diff_dir_2 / 'summary_heatmap.png',\n",
    "    plot_type='heatmap'\n",
    ")\n",
    "\n",
    "visualizer.plot_differential_analysis(\n",
    "    diff_results_2,\n",
    "    diff_dir_2 / 'summary_barplot.png',\n",
    "    plot_type='barplot'\n",
    ")\n",
    "\n",
    "print(\"Differential analysis visualizations completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Export Results\n",
    "\n",
    "Export all results in multiple formats for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export all results\n",
    "print(\"Exporting results...\")\n",
    "\n",
    "results_dir = output_dir / 'exported_results'\n",
    "integrator.export_results(results_dir, formats=['pickle', 'csv', 'json'])\n",
    "\n",
    "print(f\"Results exported to {results_dir}\")\n",
    "\n",
    "# List exported files\n",
    "print(\"\\nExported files:\")\n",
    "for file_path in sorted(results_dir.glob('*')):\n",
    "    print(f\"  {file_path.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Quality Assessment\n",
    "\n",
    "Assess the quality of the integration and analysis results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute quality metrics\n",
    "print(\"Computing quality metrics...\")\n",
    "\n",
    "quality_metrics = integrator._compute_quality_metrics()\n",
    "\n",
    "print(\"\\nQuality Assessment:\")\n",
    "for metric_type, metrics in quality_metrics.items():\n",
    "    print(f\"\\n{metric_type.replace('_', ' ').title()}:\")\n",
    "    \n",
    "    if isinstance(metrics, dict):\n",
    "        for condition, condition_metrics in metrics.items():\n",
    "            print(f\"  {condition}:\")\n",
    "            if isinstance(condition_metrics, dict):\n",
    "                for metric_name, value in condition_metrics.items():\n",
    "                    if isinstance(value, float):\n",
    "                        print(f\"    {metric_name}: {value:.4f}\")\n",
    "                    else:\n",
    "                        print(f\"    {metric_name}: {value}\")\n",
    "            else:\n",
    "                print(f\"    {condition_metrics}\")\n",
    "    else:\n",
    "        print(f\"  {metrics}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary and Interpretation\n",
    "\n",
    "Summarize the key findings from the integration analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate analysis summary\n",
    "print(\"Analysis Summary\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"\\n1. Data Integration:\")\n",
    "print(f\"   - Integrated {len(integrated_networks)} conditions\")\n",
    "print(f\"   - Conditions analyzed: {', '.join(integrated_networks.keys())}\")\n",
    "\n",
    "print(f\"\\n2. Network Statistics:\")\n",
    "for condition, network in integrated_networks.items():\n",
    "    density = nx.density(network)\n",
    "    clustering = nx.average_clustering(network) if network.number_of_nodes() > 0 else 0\n",
    "    print(f\"   {condition}: {network.number_of_nodes()} nodes, {network.number_of_edges()} edges\")\n",
    "    print(f\"     Density: {density:.4f}, Clustering: {clustering:.4f}\")\n",
    "\n",
    "print(f\"\\n3. Differential Analysis:\")\n",
    "print(f\"   - Performed {len(integrator.differential_results)} comparisons\")\n",
    "for comparison, results in integrator.differential_results.items():\n",
    "    print(f\"   {comparison}:\")\n",
    "    summary = results.get('summary', {})\n",
    "    for analysis_type, stats in summary.items():\n",
    "        significant = stats.get('significant_changes', 0)\n",
    "        print(f\"     {analysis_type}: {significant} significant changes\")\n",
    "\n",
    "print(f\"\\n4. Output Files:\")\n",
    "print(f\"   - Results exported to: {results_dir}\")\n",
    "print(f\"   - Visualizations saved to: {output_dir}\")\n",
    "\n",
    "print(f\"\\n5. Key Findings:\")\n",
    "print(f\"   - Successfully integrated regulatory and protein networks\")\n",
    "print(f\"   - Identified condition-specific network changes\")\n",
    "print(f\"   - Generated comprehensive visualizations\")\n",
    "print(f\"   - Provided quantitative differential analysis\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Analysis completed successfully!\")\n",
    "print(\"Check the output directory for detailed results and visualizations.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "This notebook demonstrated the basic workflow for SCENIC+ and PINNACLE integration. Here are some suggestions for further analysis:\n",
    "\n",
    "1. **Biological Interpretation**: \n",
    "   - Analyze the biological significance of identified regulatory changes\n",
    "   - Perform pathway enrichment analysis on differential genes/proteins\n",
    "   - Validate key findings with experimental data\n",
    "\n",
    "2. **Advanced Analysis**:\n",
    "   - Explore network modules and communities\n",
    "   - Perform time-series analysis if temporal data is available\n",
    "   - Integrate additional omics layers (metabolomics, epigenomics)\n",
    "\n",
    "3. **Visualization Enhancement**:\n",
    "   - Create interactive network visualizations\n",
    "   - Generate publication-ready figures\n",
    "   - Develop custom visualization for specific biological questions\n",
    "\n",
    "4. **Method Development**:\n",
    "   - Optimize integration parameters for your specific dataset\n",
    "   - Implement custom quality control metrics\n",
    "   - Develop specialized analysis workflows\n",
    "\n",
    "For more information and advanced tutorials, please refer to the documentation and additional examples in the repository."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

